---
title: "**Sequencing 16S rRNA gene fragments using the PacBio SMRT DNA sequencing system**"
bibliography: references.bib
output:
  pdf_document:
    includes:
      in_header: header.tex
csl: peerj.csl
fontsize: 11pt
geometry: margin=1.0in
---


```{r knitr_settings, eval=TRUE, echo=FALSE, cache=FALSE}
opts_chunk$set("tidy" = TRUE)
opts_chunk$set("echo" = FALSE)
opts_chunk$set("eval" = TRUE)
opts_chunk$set("warning" = FALSE)
opts_chunk$set("cache" = FALSE)

inline_hook <- function(x){
	print(x)
	if(is.numeric(x)){
		if(abs(x - round(x)) < .Machine$double.eps^0.5){
			paste(format(x,big.mark=',', digits=0, scientific=FALSE))
		} else {
			paste(format(x,big.mark=',', digits=1, nsmall=1, scientific=FALSE))
		}

	} else {
    	paste(x)      
	}
}
knitr::knit_hooks$set(inline=inline_hook)

regions <- c("v4", "v13", "v35", "v15", "v16", "v19")
clrs <- rainbow(length(regions))
pretty.region <- c("v13"="V1-V3", "v15"="V1-V5", "v16"="V1-V6", "v19"="V1-V9", "v35"="V3-V5", "v4"="V4")
names(clrs) <- regions
```

\vspace{35mm}

**Running title:** 16S rRNA genes sequencing with PacBio

\vspace{15mm}

**Authors:** Patrick D. Schloss^1#^, Sarah L. Westcott^1^, Matthew L. Jenior^1^,
and Sarah K. Highlander^2^

\vspace{40mm}

$\dagger$ To whom correspondence should be addressed: pschloss@umich.edu

1\. Department of Microbiology and Immunology, 1500 W. Medical Center, University of Michigan, Ann Arbor, MI 48109

2\. Genomic Medicine, J. Craig Venter Institute, 4120 Capricorn Lane, La Jolla, CA 92307


\newpage
\linenumbers


## Abstract [ Revise ]
Over the past 10 years, microbial ecologists have largely abandoned sequencing
16S rRNA genes by the Sanger sequencing method and have instead adopted highly
parallelized sequencing platforms. These new platforms, such as 454 and
Illumina's MiSeq, have allowed researchers to obtain millions of high quality,
but short sequences. These platforms have allowed researchers to significantly
improve the design of their experiments. The tradeoff has been the decline in
the number of full-length reference sequences that are deposited into databases.
To overcome this problem, we tested the ability of the PacBio Single Molecule,
Real-Time (SMRT) DNA sequencing platform to generate sequence reads from the 16S
rRNA gene. We generated sequencing data from the V4, V3-V5, V1-V3, V1-V6, and
V1-V9 variable regions from within the 16S rRNA gene from a synthetic mock
community and natural samples collected from human feces, mouse feces, and soil.
The synthetic mock community allowed us to assess the actual sequencing error
rate and how that error rate changed when different curation methods were
applied. We developed a simple method based on sequence characteristics and
quality scores to reduce the observed error rate for the V1-V9 region from 2.16%
to 0.32%. Unfortunately, this error rate was still 16-times higher than the
error rate that has been observed for the shorter reads generated by 454 and
Illumina's MiSeq sequencing platforms. Although the longer reads frequently
provided better classification, the wider adoption of this approach for 16S rRNA
gene sequencing is likely limited by its high sequencing error and low yield of
sequencing data relative to the other available platforms.


***Keywords:*** Microbial ecology, bioinformatics, sequencing error



## Introduction [ Revise ]
Advances in sequencing technologies over the past 10 years have introduced
considerable advances to the field of microbial ecology. Clone-based Sanger
sequencing of the 16S rRNA gene has largely been replaced by various platforms
produced by 454/Roche {e.g. Sogin, 2006 #1510}, Illumina
{e.g. Gloor, 2010 #2611}, and IonTorrent {e.g. Junemann, 2012 #2630}. It was
once common to sequence fewer than 100 16S rRNA gene sequences from several
samples using the Sanger approach {e.g. McCaig, 1999 #592}. Now it is common to
generate thousands of sequences from each of several hundred samples
{The Human Microbiome Consortium, 2012 #2617}. The advance in throughput has
come at the cost of read length. Sanger sequencing regularly generated 800 nt
per read and because the DNA was cloned, it was possible to obtain multiple
reads per fragment to yield a full-length sequence from a representative single
molecule. At approximately $8 (US) per sequencing read, most
researchers have effectively decided that full-length sequences are not worth
the increased cost relative to the cost of more recently developed approaches.
There is still a clear need to generate high-throughput full-length sequence
reads that are of sufficient quality that they can be used as references for
analyses based on obtaining short sequence reads.

Historically, all sequencing platforms were created to primarily perform genome
sequencing. When sequencing a genome, it is assumed that the same base of DNA
will be sequenced multiple times and the consensus of multiple sequence reads is
used to generate contigs. Thus, although an individual base call may have a high
error rate, the consensus sequence will have a low error rate. To sequence the
16S rRNA gene researchers use conserved primers to amplify a sub-region from
within the gene that is isolated from many organisms. Because the fragments
are not cloned, it is not possible to obtain high sequence coverage from the
same DNA molecule using these platforms. Thus, to reduce sequencing error rates
it has become imperative to develop stringent sequence curation and denoising
algorithms {Kozich, 2013 #2719; Schloss, 2011 #2466}. There has been a tradeoff
between read length, number of reads per sample, and the error rate. For
instance, we recently demonstrated that using the Illumina MiSeq and the 454
Titanium platforms the raw error rate varies between 1 and 2% {Kozich, 2013
#2719; Schloss, 2011 #2466}. Yet, it was possible to obtain error rates below
0.02% by adopting various denoising algorithms. However, the resulting fragments
were only 250-nt long. In the case of 454 Titanium, extending the length of the
fragment introduces length-based errors and in the case of the Illumina MiSeq,
increasing the length of the fragment reduces the overlap between the read pairs
reducing the ability of each read to mutually reduce the sequencing error.
Inadequate denoising of sequencing reads can have many negative effects
including limited ability to identify chimeras {Haas, 2011 #2404;Edgar, 2011 #2406}
and inflation of alpha- and beta-diversity metrics
{Huse, 2010 #2034; Kunin, 2010 #2259; Kozich, 2013 #2719; Schloss, 2011 #2466}.
Although MiSeq and 454 enjoy widespread use in the field, the MiSeq
platform is emerging as the leader because of the ability to sequence 15-20
million fragments that can be distributed across hundreds of samples for less
than $5000 (US).

As these sequencing platforms have grown in popularity, there has been a decline
in the number of full-length 16S rRNA genes being deposited into GenBank that
could serve as references. This is particularly frustrating since the
technologies have significantly improved our ability to detect and identify
novel populations for which we lack full-length reference sequences. A related
problem is the perceived limitation that the short reads generated by the 454
and Illumina platforms cannot be reliably classified to the genus or
species level. Previous investigators have utilized simulations to
demonstrate that increased read lengths usually increase the accuracy and
sensitivity of classification against reference databases
{Liu, 2008 #2188;Werner, 2012 #2474;Wang, 2007 #1809}. There is
clearly a need to develop sequencing technologies that will allow researchers to
generate high quality full-length 16S rRNA gene sequences in a high throughput
manner.

New advances in single molecule sequencing technologies, such as the platform
produced by Pacific Biosciences (PacBio), offer the opportunity to once again
obtain full-length sequence reads with a high depth of coverage from a large
number of samples. To this point, the PacBio Single Molecule, Real-Time (SMRT)
DNA Sequencing System has received limited application in the microbial ecology
research domain {Mosher, 2014 #3376; Fichot, 2013 #3453; Mosher, 2013 #3454}.
The SMRT system ligates hairpin adapters (i.e. SMRTbells) to the ends of
double-stranded DNA. Although the DNA molecule is linear, it is effectively
circularized allowing the sequencing polymerase to process around the molecule
multiple times {Au, 2012 #3455}. According to Pacific Biosciences the platform
is able to generate median read lengths longer than 8 kb with the P4-C2
chemistry; however, the single pass error rate is approximately 15%. Given the
circular nature of the DNA fragment, the full read length can be used to cover
the DNA fragment multiple times resulting in a reduced error rate. Therefore,
one should be able to obtain multiple coverage of the full 16S rRNA gene at a
reduced error rate.

Despite the opportunity to potentially generate high-quality full-length
sequences, the Pacific Biosciences platform has not been widely adopted for
sequencing 16S rRNA genes {Fichot, 2013 #3453; Mosher, 2014 #3376; Mosher, 2014 #3376}.
Previous studies utilizing the technology have removed reads with mismatched
primers and barcodes, ambiguous base  calls, and low quality scores {Fichot, 2013 #3453}.
Others have utilized the platform without describing the bioinformatic pipeline
that was utilized {Mosher, 2014 #3376; Mosher, 2014 #3376}. Regardless of the
curation methods, the error rates associated with sequencing the 16S rRNA gene
on the platform have never been reported. In the current study, we assessed the
quality of data generated by the Pacific Biosciences sequencer and whether it
could fill the need for generating high-quality, full-length sequence data. We
hypothesized that by modulating the 16S rRNA gene fragment length we could alter
the read depth and obtain reads longer than are currently available by the 454
and Illumina platforms but with the same quality. To test this hypothesis, we
developed a sequence curation pipeline that was optimized by reducing the
sequencing error rate of a mock bacterial community with known composition. The
resulting pipeline was then applied to 16S rRNA gene fragments that were
isolated from soil and human and mouse feces.


## Materials and Methods
***Community DNA.*** We utilized genomic DNA isolated from four communities.
These same DNA extracts were previously used to develop an Illumina MiSeq-based
sequencing strategy {Kozich, 2013 #2719}.  Briefly, we used a “Mock Community”
composed of genomic DNA from 21 bacterial strains: *Acinetobacter baumannii*
ATCC 17978, *Actinomyces odontolyticus* ATCC 17982, *Bacillus cereus* ATCC
10987, *Bacteroides vulgatus* ATCC 8482, *Clostridium beijerinckii* ATCC 51743,
*Deinococcus radiodurans* ATCC 13939, *Enterococcus faecalis* ATCC 47077,
*Escherichia coli* ATCC 70096, *Helicobacter pylori* ATCC 700392, *Lactobacillus
gasseri* ATCC 33323, *Listeria monocytogenes* ATCC BAA-679, *Neisseria
meningitidis* ATCC BAA-335, *Porphyromonas gingivalis* ATCC 33277,
*Propionibacterium acnes* DSM 16379, *Pseudomonas aeruginosa* ATCC 47085,
*Rhodobacter sphaeroides* ATCC 17023, *Staphylococcus aureus* ATCC BAA-1718,
*Staphylococcus epidermidis* ATCC 12228, *Streptococcus agalactiae* ATCC
BAA-611, *Streptococcus mutans* ATCC 700610, *Streptococcus pneumoniae* ATCC
BAA-334. The mock community DNA is available through BEI resources (v3.1,
HM-278D). Genomic DNAs from the three other communities were obtained using the
MO BIO PowerSoil DNA extraction kit. The human and mouse fecal samples were
obtained using protocols that were reviewed and approved by the University
Committee on Use and Care of Animals (Protocol #PRO00004877) and the
Institutional Review Board at the University of Michigan (Protocol
#HUM00057066). The human stool donor provided informed consent.

***Library generation and sequencing.*** [ Revise ]
The DNAs were each amplified in triplicate using barcoded primers targeting the
V4, V1-V3, V3-V5, V1-V5, V1-V6, and V1-V9 variable regions (Table 1). The
primers were synthesized so that the 5’ end of the forward and reverse primers
were each tagged with a 5-nt barcode sequence to allow multiplexing of samples
within a single sequencing run. Methods describing PCR, amplicon cleanup, and
pooling were described previously {Kozich, 2013 #2719}. The SMRTbell adapters
were ligated onto  the PCR products and the libraries were sequenced by Pacific
Biosciences using the P6-C24 chemistry on a PacBio RS II SMRT DNA Sequencing
System.


***Data analysis.***  [ Revise ]
All sequencing data were curated using mothur {Schloss, 2009 #1816} and analyzed
using the R programming language {R Core Team, 2014 #3456}. The raw data can be
obtained from the Sequence Read Archive at NCBI under accession SRP051686, which
are associated with BioProject PRJNA271568. Several specific features were
incorporated into mothur to facilitate the analysis of PacBio  sequence data.
First, because non-ambiguous base calls are assigned to Phred quality scores of
zero, the consensus fastq files were parsed so that scores of zero were
interpreted as corresponding to an ambiguous base call (i.e. N) in the
fastq.info command using the pacbio=T option. Second, because the consensus
sequence can be generated in the forward and reverse complement orientations, a
checkorient option was added to the trim.seqs command in order to identify the
proper orientation. These features were incorporated into mothur v.1.30. Because
chimeric molecules can be generated during PCR and would artificially inflate
the sequencing error, it was necessary to remove these data prior to assessing
the error rate. Because we knew the true sequences for the strains in the mock
community we could calculate all possible chimeras between strains in the mock
community (*in silico* chimeras). If a sequence read was 3 or more nucleotides
more similar to an *in silico* chimera than it was to a non-chimeric reference
sequence, it was classified as a chimera and removed from further consideration.
Identification of *in silico* chimeras and calculation of sequencing error rates
was performed using the seq.error command in mothur {Schloss, 2011 #2466}. *De
novo* chimera detection was also performed on the mock and other sequence data
using the abundance-based algorithm implemented in UCHIME {Edgar, 2011 #2406}.
Sequences sequences were aligned against a SILVA-based reference alignment
{Pruesse, 2007 #1735} using a profile-based aligner {Schloss, 2009 #1825} and
were classified against the SILVA {Pruesse, 2007 #1735}, RDP {Cole, 2014 #3460},
and greengenes {Werner, 2012 #2474} reference taxonomies  using a naive Bayesian
classifier {Wang, 2007 #1809}. Sequences were assigned to operational taxonomic
units using the average neighbor clustering algorithm with a 3% distance
threshold {Schloss, 2011 #3156}.  Detailed methods including this paper as an R
markdown file are available as a public online repository
(http://github.com/SchlossLab/ Schloss_PacBio16S_PeerJ_2015).


## Results and Discussion

```{r error_profile}
sub.matrix <- read.table(file=paste("pipeline_dev/", regions[1], "/", regions[1], ".mock.filter.error.matrix", sep=""), header=T, row.names=1)[-7,]
for(i in 2:length(regions)){
	sub.matrix <- sub.matrix + read.table(file=paste("pipeline_dev/", regions[i], "/", regions[i], ".mock.filter.error.matrix", sep=""), header=T, row.names=1)[-7,]
}

matches <- c(sub.matrix[1,1], sub.matrix[2,2], sub.matrix[3,3], sub.matrix[4,4])
total <- sum(sub.matrix)
errors <- sub.matrix
diag(errors[1:4,1:4]) <- 0
init.error.rate <- 100 * sum(errors) / total				#1.925717

subst.bias <- apply(errors[1:4,1:4], 2, sum)/apply(sub.matrix[1:4,1:4], 2, sum)
subst.bias <- 100 * subst.bias/sum(subst.bias)
#       rA        rT        rG        rC
# 22.43918 27.21620 24.06557 26.27904
#these are more or less equal to each other

insert.bias <- (sub.matrix[,"rGap"]/apply(sub.matrix, 1, sum))[1:4]
insert.bias <- 100 * insert.bias/sum(insert.bias)
#       qA       qT       qG       qC
# 23.46112 24.36667 24.33064 27.84157
#these are more or less equal to each other

delete.bias <- (sub.matrix["qGap",]/apply(sub.matrix, 2, sum))[1:4]
delete.bias <- 100 * delete.bias/sum(delete.bias)
#           rA      rT       rG       rC
#qGap 11.43234 9.46907 44.57506 34.52353
#interestingly the G's and C's are more likely to be deleted than the As or Ts

substitutions <- 100*sum(errors[1:4,1:4])/sum(errors)	#35.80084
insertions <- 100*sum(errors[,5])/sum(errors)			#45.27368
deletions <- 100*sum(errors[5,])/sum(errors)			#17.27259
ambiguous <- 100*sum(errors[6,])/sum(errors)			#2.101505


# Need to connect error types with the quality scores
error.quality <- read.table(file=paste("pipeline_dev/", regions[1], "/", regions[1], ".mock.filter.error.quality", sep=""), header=T, row.names=1)[-7,]
for(i in 2:length(regions)){
	error.quality <- error.quality + read.table(file=paste("pipeline_dev/", regions[i], "/", regions[i], ".mock.filter.error.quality", sep=""), header=T, row.names=1)[-7,]
}
error.quality["72",] <- error.quality["72",] + error.quality["80",]
error.quality <- error.quality[1:72,]

#get quantiles
matches <- rep(as.numeric(rownames(error.quality)), error.quality$matches)
m.quant <- quantile(matches, prob=c(0.025, 0.25, 0.5, 0.75, 0.975))

subs <- rep(as.numeric(rownames(error.quality)), error.quality$substitutions)
s.quant <- quantile(subs, prob=c(0.025, 0.25, 0.5, 0.75, 0.975))

ins <- rep(as.numeric(rownames(error.quality)), error.quality$insertions)
i.quant <- quantile(ins, prob=c(0.025, 0.25, 0.5, 0.75, 0.975))

ambig <- rep(as.numeric(rownames(error.quality)), error.quality$ambiguous)
a.quant <- quantile(ambig, prob=c(0.025, 0.25, 0.5, 0.75, 0.975))
```
***The PacBio error profile.***
To build a sequence curation pipeline, we first needed to characterize the error
rate associated with sequencing the 16S rRNA gene. We observed an average
sequencing error rate of `r format(init.error.rate, digits=3, nsmall=2)`%. Insertions, deletions, substitutions, and ambiguous base calls
accounted for `r format(insertions, digits=3, nsmall=1)`,
`r format(deletions, digits=3, nsmall=1)`, `r format(substitutions, digits=3, nsmall=1)`,
and `r format(ambiguous, digits=2, nsmall=1)`% of
the errors, respectively. The substitution errors were equally likely and all four bases
were equally likely to cause insertion errors. Interestingly, guanines
(`r format(delete.bias["rG"], digits=3, nsmall=1)`%) and cytosines
(`r format(delete.bias["rC"], digits=3, nsmall=1)`%) were more likely to be deleted
than adenines (`r format(delete.bias["rA"], digits=3, nsmall=1)`%) or thymidines
(`r format(delete.bias["rT"], digits=2, nsmall=1)`%). When we considered the Phred
quality score of each base call, we observed a median quality score of `r m.quant["50%"]`
for correct base calls and scores of `r s.quant["50%"]` and `r i.quant["50%"]` for
substitutions and insertions, respectively (Figure 1A). Although there
was a broad distribution of quality scores with each type of base call, the errors could
largely be distinguished from the correct base calls.


```{r initialError}
getInitError <- function(folder){
	error <- read.table(file=paste("pipeline_dev/", folder, "/", folder, ".mock.filter.error.summary", sep=""), header=T, row.names=1)
	error <- error[error$numparents==1,]
	return(sum(error$mismatches)/sum(error$total))
}

init.rates <- unlist(lapply(regions, getInitError))
names(init.rates) <- regions

getReasonsLost <- function(region){
	composite <- read.table(file=paste("pipeline_dev/", region, "/", region, ".composite", sep=""), header=T, row.names=1)
	reasons <- as.character(composite$reason)

	nseqs <- length(reasons)
	good <- sum(reasons=="g")	/ nseqs
	start.stop <- sum(grepl("s", reasons) | grepl("e", reasons)) / nseqs
	homop <- length(grep("h", reasons)) / nseqs
	ambig <- length(grep("n", reasons)) / nseqs
	return(c(good=good, start.stop=start.stop, homop=homop, ambig=ambig, ngood=nseqs))
}

reasons.lost <- matrix(unlist(lapply(regions, getReasonsLost)), ncol=5, byrow=T)
colnames(reasons.lost) <- c("good", "start.stop", "homop", "ambig", "nseqs")
rownames(reasons.lost) <- regions

orig.nseqs <- reasons.lost[,"nseqs"]
basic.nseqs <- orig.nseqs * reasons.lost[,1]
reasons.lost <- reasons.lost[,-5]

getBasicError <- function(folder){
	composite <- read.table(file=paste("pipeline_dev/", folder, "/", folder, ".composite", sep=""), header=T, row.names=1)
	good <- composite[composite$reason == "g",]
	return(sum(good$mismatches)/sum(good$total))
}

basic.error <- unlist(lapply(regions, getBasicError))
names(basic.error) <- regions
#         v4         v13         v35         v15         v16         v19
#0.005373722 0.014743697 0.013730112 0.009027326 0.014249660 0.013027623
composite.basic.error <- 100 * sum(basic.error*basic.nseqs)/(sum(basic.nseqs))
```

***A basic sequence curation procedure.***
To establish a simple curation procedure, we culled any sequence that contained
an ambiguous base call, had a string of the same base repeated 9 or more times,
did not start and end at the expected alignment coordinates for that region
of the 16S rRNA gene, or that was chimeric. This reduced the experiment-wide
error rate from `r format(init.error.rate, digits=3, nsmall=2)` to
`r format(composite.basic.error, digits=2, nsmall=2)`%. This basic procedure
resulted in the removal of between
`r format(round(min(100*(1-reasons.lost[,"good"])), digits=1), nsmall=1)`
(`r pretty.region[names(which.min(100*(1-reasons.lost[,"good"])))]`) and
`r round(max(100*(1-reasons.lost[,"good"])), digits=1)`
(`r pretty.region[names(which.max(100*(1-reasons.lost[,"good"])))]`)% of the
reads. The percentage of reads removed increased with the length of the
fragment (Figure 2). The number of reads removed
because of the presence of ambiguous base calls was similar to the number of
reads that were removed for not fully aligning to the correct region within the
16S rRNA gene (Table 2). The latter class of errors was
generally due to sequence truncations that could not be explained.  


```{r barcodePrimerAnalysis}
getFragment_BPErrorRates <- function(folder){
	composite <- read.table(file=paste("pipeline_dev/", folder, "/", folder, ".composite", sep=""), header=T, row.names=1)
	composite <- composite[composite$reason == "g",]
	bc.primer <- composite$fbdiffs + composite$rbdiffs + composite$fpdiffs + composite$rpdiffs

	return(cbind(composite$error, bc.primer))
}

errors <- lapply(regions, getFragment_BPErrorRates)

errors.table <- matrix(errors[[1]], ncol=2, byrow=F)
err.bcprimer <- aggregate(100*errors.table[,1], by=list(errors.table[,2]),
													function(x){c(mean(x), length(x))})

getBCPrimerError <- function(folder){
	composite <- read.table(file=paste("pipeline_dev/", folder, "/", folder,
																		 ".composite", sep=""), header=T, row.names=1)
	composite <- composite[composite$reason == "g",]
	mismatch <- composite$fbdiffs + composite$rbdiffs + composite$fpdiffs + composite$rpdiffs

	good0 <- mismatch == 0
	composite.good0 <- composite[good0,]

	good1 <- mismatch <= 1
	composite.good1 <- composite[good1,]

	return(c(mean(composite.good0[,"error"]), nrow(composite.good0)/nrow(composite),
	mean(composite.good1[,"error"]), nrow(composite.good1)/nrow(composite) ))
}

bcprimer.error <- matrix(unlist(lapply(regions, getBCPrimerError)), nrow=6, byrow=T)
rownames(bcprimer.error) <- regions
colnames(bcprimer.error) <- c("0.error", "0.frac", "1.error", "1.frac")

#         0.error    0.frac     1.error    1.frac
# v4  0.002616919 0.6417469 0.003711755 0.9081720
# v13 0.011102712 0.5799452 0.012493713 0.8675194
# v35 0.010838504 0.6464069 0.011901910 0.8934573
# v15 0.005375053 0.5079055 0.007029568 0.8338150
# v16 0.010374438 0.5456238 0.011893323 0.8609559
# v19 0.008543379 0.5072207 0.010086351 0.8237548
```
```{r coverageAnalysis}
errorAtCoverageCutoff <- function(folder){
	composite <- read.table(file=paste("pipeline_dev/", folder, "/", folder, ".composite", sep=""), header=T, row.names=1)
	composite <- composite[composite$reason == "g",]

	total.seqs <- nrow(composite)

	deep <- composite$freq >= 10
	composite <- composite[deep,]

	covered.seqs <- nrow(composite)

	error <- sum(composite$mismatches)/sum(composite$total)
	frac.kept <- covered.seqs / total.seqs
	return(c(error=error, kept=frac.kept))
}

coverage.error <- unlist(lapply(regions, errorAtCoverageCutoff))
coverage.error <- matrix(coverage.error, ncol=2, byrow=T)
rownames(coverage.error) <- regions
colnames(coverage.error) <- c("10.error", "10.frac")

#       10.error   10.frac
#v4  0.002524566 0.7897874
#v13 0.010359113 0.6592051
#v35 0.010084961 0.6642832
#v15 0.006534609 0.6717103
#v16 0.010039601 0.4605835
#v19 0.009506114 0.5620395


coverage.reduction <- (1-coverage.error[,"10.error"]/basic.error)*100
#      v4      v13      v35      v15      v16      v19
#53.02015 29.73870 26.54859 27.61302 29.54498 27.03110
```
```{r qualityScoreAnalysis}
getErrorRateFromAveQ <- function(folder, threshold=60){
	write(folder, "")
	composite <- read.table(file=paste("pipeline_dev/", folder, "/", folder, ".composite", sep=""), header=T, row.names=1)
	composite <- composite[composite$reason == "g",]

	rates <- composite[composite$aveQ >= threshold,]

	remaining.error <- mean(rates[,"error"])
	fraction.kept <- nrow(rates)/nrow(composite)

	return(c(remaining.error, fraction.kept))
}

aveq.error <- matrix(unlist(lapply(regions, getErrorRateFromAveQ)), ncol=2, byrow=T)
rownames(aveq.error) <- regions
colnames(aveq.error) <- c("60.error", "60.frac")

#       60.error   60.frac
#v4  0.002623098 0.8692667
#v13 0.009914371 0.7608497
#v35 0.009035060 0.7697533
#v15 0.004553350 0.7005270
#v16 0.008921902 0.6561142
#v19 0.005714256 0.5010315

quality.reduction <- (1-aveq.error[,"60.error"]/basic.error)*100
```
```{r oligosCoverageAnalysis}
oligosCoverage <- function(folder){
	write(folder, "")
	composite <- read.table(file=paste("pipeline_dev/", folder, "/", folder, ".composite", sep=""), header=T, row.names=1)
	composite <- composite[composite$reason == "g",]

	mismatch <- composite$fbdiffs + composite$rbdiffs + composite$fpdiffs + composite$rpdiffs
	good0 <- mismatch == 0 & composite$freq >= 10
	composite.good0 <- composite[good0,]

	good1 <- mismatch <= 1 & composite$freq >= 10
	composite.good1 <- composite[good1,]

	return(c(mean(composite.good0[,"error"]), nrow(composite.good0)/nrow(composite),
	mean(composite.good1[,"error"]), nrow(composite.good1)/nrow(composite) ))
}

oligosCoverage.error <- matrix(unlist(lapply(regions, oligosCoverage)), ncol=4, byrow=T)
rownames(oligosCoverage.error) <- regions
colnames(oligosCoverage.error) <- c("0.10.error", "0.10.frac", "1.10.error", "1.10.frac")

#     0.10.error 0.10.frac  1.10.error 1.10.frac
#v4  0.001565052 0.5567846 0.002068184 0.7513111
#v13 0.009371691 0.4353586 0.009899256 0.6180905
#v35 0.009096211 0.4907043 0.009503092 0.6321058
#v15 0.004050098 0.3803978 0.005253236 0.5899354
#v16 0.007945951 0.2960894 0.008956478 0.4301676
#v19 0.006706336 0.3188918 0.007903900 0.4927793
```
```{r oligosQScoreAnalysis}
oligosQScore <- function(folder){
	write(folder, "")
	composite <- read.table(file=paste("pipeline_dev/", folder, "/", folder, ".composite", sep=""), header=T, row.names=1)
	composite <- composite[composite$reason == "g",]

	mismatch <- composite$fbdiffs + composite$rbdiffs + composite$fpdiffs + composite$rpdiffs

	good <- mismatch == 0 & composite$aveQ >= 60
	composite.good0 <- composite[good,]

	good1 <- mismatch <= 1 & composite$aveQ >= 60
	composite.good1 <- composite[good1,]

	return(c(mean(composite.good0[,"error"]), nrow(composite.good0)/nrow(composite),
	mean(composite.good1[,"error"]), nrow(composite.good1)/nrow(composite) ))
}

oligosQScore.error <- matrix(unlist(lapply(regions, oligosQScore)), ncol=4, byrow=T)
rownames(oligosQScore.error) <- regions
colnames(oligosQScore.error) <- c("0.60.error", "0.60.frac", "1.60.error", "1.60.frac")

#     0.60.error 0.60.frac  1.60.error 1.60.frac
#v4  0.001715135 0.6015066 0.002215499 0.8232097
#v13 0.009153895 0.5013705 0.009700915 0.7108269
#v35 0.008365403 0.5557740 0.008690839 0.7281015
#v15 0.003217812 0.4102346 0.003993206 0.6282727
#v16 0.007589961 0.4115456 0.008358922 0.6101800
#v19 0.004870705 0.3209549 0.005294429 0.4653699
```
```{r coverageQScoreAnalysis}
coverageQScore <- function(folder){
	write(folder, "")
		composite <- read.table(file=paste("pipeline_dev/", folder, "/", folder, ".composite", sep=""), header=T, row.names=1)
		composite <- composite[composite$reason == "g",]

	good <- composite$freq >= 10 & composite$aveQ>= 60
	composite.good <- composite[good,]

	return(c(mean(composite.good[,"error"]), nrow(composite.good)/nrow(composite) ))
}

coverageQScore.error <- matrix(unlist(lapply(regions, coverageQScore)), ncol=2, byrow=T)
rownames(coverageQScore.error) <- regions
colnames(coverageQScore.error) <- c("10.60.error", "10.60.frac")

#    10.60.error 10.60.frac
#v4  0.002361882  0.7874988
#v13 0.010016818  0.6541800
#v35 0.009296289  0.6564176
#v15 0.004481083  0.5824549
#v16 0.009612120  0.4587213
#v19 0.005692918  0.3884468
```
```{r allFiltersAnalysis}
allFilters <- function(folder){
write(folder, "")
		composite <- read.table(file=paste("pipeline_dev/", folder, "/", folder, ".composite", sep=""), header=T, row.names=1)
		composite <- composite[composite$reason == "g",]
	mismatch <- composite$fbdiffs + composite$rbdiffs + composite$fpdiffs + composite$rpdiffs

good0 <- mismatch == 0 & composite$aveQ>= 60 & composite$freq >= 10
composite.good0 <- composite[good0,]

good1 <- mismatch <= 1 & composite$aveQ >= 60 & composite$freq >= 10
composite.good1 <- composite[good1,]

return(c(mean(composite.good0[,"error"]), nrow(composite.good0)/nrow(composite),
mean(composite.good1[,"error"]), nrow(composite.good1)/nrow(composite) ))
}

allFilters.error <- matrix(unlist(lapply(regions, allFilters)), ncol=4, byrow=T)
rownames(allFilters.error) <- regions
colnames(allFilters.error) <- c("0.10.60.error", "0.10.60.frac", "1.10.60.error", "1.10.60.frac")

#    0.10.60.error 0.10.60.frac 1.10.60.error 1.10.60.frac
#v4    0.001515500    0.5562125   0.001993325    0.7499762
#v13   0.009299146    0.4337597   0.009827404    0.6155779
#v35   0.008613200    0.4862353   0.008979207    0.6253128
#v15   0.003078476    0.3488609   0.003905562    0.5268616
#v16   0.007738039    0.2954687   0.008814923    0.4295469
#v19   0.004797594    0.2496316   0.005266467    0.3631005
```

***Identifying correlates of increased sequencing error.***
In contrast to the 454 and Illumina-based platforms where the sequencing
quality decays with length, the consensus sequencing approach employed by the
PacBio sequencer is thought to generate a uniform distribution of errors. This
makes it impossible to simply trim sequences to high quality regions. Therefore,
we sought to identify characteristics within sequences that would allow us to
identify and remove those sequences with errors using three different
approaches. First, we hypothesized that errors in the barcode and primer would
be correlated with the error rate for the entire sequence. We observed a strong
relationship between the number of mismatches to the barcodes and primers and the
error rate of the rest of the sequence fragment (Figure 1B). Although
allowing no mismatches to the barcodes and primers yielded the lowest error rate,
that stringent criterion removed a large fraction of the reads from the dataset and
allowing at most one mismatch marginally increased the error rate while preserving
more sequences in the dataset (Figure 2). Second, we hypothesized
that increased sequencing coverage should yield lower error rates. We found that
once we had obtained 10-fold coverage of the fragments, the error rate did not
change appreciably (Figure 1C). When we compared the error
rates of reads with at least 10-fold coverage to those with less coverage, we
reduced the error rate by
`r paste(round(sort(coverage.reduction)[c(1,5)], digits=1), collapse=" to ")`%
for each region except the V4 region for which the error rate was reduced by
`r round(coverage.reduction["v4"], digits=1)`%. Third, based on the earlier
analysis associating errors with quality scores, we used two quality score-based
approaches for identifying reads with errors (Figure 3). We calculated the
minimum average quality score across all 50-nt windows within each sequence and
we also calculated the average quality score across each sequence. We then
associated both methods of calculating the average quality score with the error
rate of the reads and the fraction of sequences that would be retained if each
threshold were selected. Using the sliding window approach we did not observe
any clear break points indicating that one quality score would be better than
another (Figure 3AB). In contrast, using the whole sequence quality score
average we observed a decrease in the error rate and the fraction of sequences
retained when the threshold was increased above 60 (Figure 3CD). When we used
this threshold, we were able to reduce the error rate by
`r paste(round(range(quality.reduction), digits=1), collapse=" to ")`%
(Figure 2A). We noted that the fraction of reads retained
decreased as the length of the fragment increased with retention of
`r round(100*aveq.error["v4", "60.frac"],digits=1)`% of the V4 reads and
`r round(100*aveq.error["v19", "60.frac"],digits=1)`% of the V1-V9 reads (Figure
2B). Next, we asked whether which combinations of culling reads with mismatches
to the expected barcodes and primers, less than 10-fold sequencing coverage, and
an average quality score less than 60 made the most meaningful reductions in the
error rate while preserving the most reads when implemented with the basic
curation pipeline (Figure 2B). We observed similar error rates when we required
one or fewer mismatches to the barcodes and primers and an average quality score
above 60 as when we also required a minimum 10-fold coverage. Culling sequences
that had more than one mismatch to the barcodes and primers and those with an
average quality score less than 60 reduced the error rate to between
`r paste(round(100*range(oligosQScore.error[,"1.60.error"]), digits=2), collapse=" and ")`.
This procedure resulted in the removal of
`r paste(rev(round(100*(1-range(oligosQScore.error[,"1.60.frac"])), digits=0)), collapse=" and ")`%
of the reads (Figure 2). The remainder of this paper uses this sequence curation
approach.


```{r precluster}
summarizeError <- function(folder, method){
  file1 <- paste("analysis/", folder, "/", folder, ".mock1.", method, ".error.summary", sep="")
  file2 <- paste("analysis/", folder, "/", folder, ".mock2.", method, ".error.summary", sep="")
  file3 <- paste("analysis/", folder, "/", folder, ".mock3.", method, ".error.summary", sep="")

  summary <- rbind(read.table(file=file1, header=T, row.names=1), read.table(file=file2, header=T, row.names=1), read.table(file=file3, header=T, row.names=1))
  nochim <- summary[summary$numparents==1,]
  error <- sum(nochim$weight * nochim$mismatches) / sum(nochim$weight * nochim$total)
  return(error)
}

unique.error <- unlist(lapply(regions, summarizeError, "unique"))
precluster.error <- unlist(lapply(regions, summarizeError, "precluster"))
final.error <- cbind(unique.error, precluster.error)
rownames(final.error) <- regions

#    unique.error precluster.error
#v4   0.002277391      0.001418871
#v13  0.009081866      0.007722886
#v35  0.009719159      0.008257968
#v15  0.004740243      0.002645747
#v16  0.007130228      0.005676505
#v19  0.005158478      0.003163881


reduction <- 100*(1-final.error[,"precluster.error"]/final.error[,"unique.error"])
rnd.reduction <- round(reduction, 0)
min.rnd.red <- min(rnd.reduction)
max.rnd.red <- max(rnd.reduction)

min.region <- paste(pretty.region[names(rnd.reduction[rnd.reduction==min.rnd.red])],collapse=" and ")

max.region <- pretty.region[[names(rnd.reduction[rnd.reduction==max.rnd.red])]]
```

***Pre-clustering sequences to further reduce sequencing noise.***
Previously, we implemented a pre-clustering algorithm where sequences were sorted
by their abundance in decreasing order and rare sequences are clustered with a
more abundant sequence if the rare sequences have fewer mismatches than a
defined threshold when compared to the more abundant sequence. The recommended
threshold was a 1-nt difference per 100-nt of sequence data. For example, the
threshold for 250 bp fragment from the V4 region would be 2 nt or 14 for the
1458 bp V1-V9 fragments. This approach removes residual PCR and sequencing
errors while not overwhelming the resolution needed to identify OTUs that are
based on a 3% distance threshold. The tradeoff of this approach is that one would
unable to differentiate V1-V9 sequences that truly differed by less than 14 nt.
When we applied
this approach to our PacBio data, we observed a reduction in the error rate
between `r min.rnd.red` (`r min.region`) and `r max.rnd.red`% (`r max.region`).
The final error rates varied between
`r round(min(100*final.error[,"precluster.error"]), digits=2)`
(`r pretty.region[names(which.min(final.error[,"precluster.error"]))]`)
and `r round(max(100*final.error[,"precluster.error"]), digits=2)`%
(`r pretty.region[names(which.max(final.error[,"precluster.error"]))]`); the
full-length, V1-V9, fragments had an error rate of
`r round(100* final.error["v19","precluster.error"], digits=2)`%
(Figure 2B). These error rates are 7-40
times higher than what we have previously observed using the 454 and
Illumina MiSeq platforms (0.02%){Schloss, 2011 #2466; Kozich, 2013 #2719}



```{r}
getOTUResults <- function(region){
  perfect <- read.table(file=paste0("analysis/", region, "/HMP_MOCK.filter.pick.phylip.an.summary"), header=T)
  nochims <- read.table(file=paste0("analysis/", region, "/", region, ".mock.precluster.perfect.pick.an.ave-std.summary"), header=T)
  observed <- read.table(file=paste0("analysis/",region, "/", region, ".trim.unique.good.filter.unique.precluster.pick.an.merge.groups.ave-std.summary"), header=T)
	obs.mock <- observed[observed$group=="mock"   & observed$method=="ave", "sobs"]
	obs.soil <- observed[observed$group=="soil"   & observed$method=="ave", "sobs"]
	obs.mouse <- observed[observed$group=="mouse" & observed$method=="ave", "sobs"]
	obs.human <- observed[observed$group=="human" & observed$method=="ave", "sobs"]
	nseqs <- nochims[nochims$method=="ave", "nseqs"]

	return(c(perfect[1,2], nochims[1,3], obs.mock, obs.soil, obs.mouse, obs.human, nseqs))
}

otu.table <- t(sapply(regions, getOTUResults))
nseqs <- otu.table[1,7]
perfect.otu <- otu.table[1,1]
otu.table <- otu.table[,-c(1,7)]

otu.table <- cbind(100 * final.error[rownames(otu.table),"precluster.error"], otu.table)
colnames(otu.table) <- c("Error Rate (%)", "Mock with no chimeras", "Observed mock", "Soil", "Mouse", "Human")
rownames(otu.table) <- pretty.region[rownames(otu.table)]

#kable(otu.table, digits=c(2, rep(1,5)))

#|      | Error Rate (%)| Mock with no chimeras| Observed mock|  Soil| Mouse| Human|
#|:-----|--------------:|---------------------:|-------------:|-----:|-----:|-----:|
#|V4    |           0.14|                  26.0|          27.4| 335.8|  78.5|  58.1|
#|V1-V3 |           0.77|                  53.6|          77.0| 436.6| 159.7| 116.8|
#|V3-V5 |           0.83|                  83.1|         106.8| 388.9| 259.6|  91.6|
#|V1-V5 |           0.26|                  34.6|          40.7| 403.2|  88.8|  74.7|
#|V1-V6 |           0.57|                  57.4|          89.7| 431.9| 138.3|  95.9|
#|V1-V9 |           0.32|                  29.5|          41.8| 390.9|  81.9| 102.0|

getCoverage <- function(region){
  observed <- read.table(file=paste0("analysis/",region, "/", region, ".trim.unique.good.filter.unique.precluster.pick.an.merge.groups.ave-std.summary"), header=T)
	obs.mock <- observed[observed$group=="mock"   & observed$method=="ave", "coverage"]
	obs.soil <- observed[observed$group=="soil"   & observed$method=="ave", "coverage"]
	obs.mouse <- observed[observed$group=="mouse" & observed$method=="ave", "coverage"]
	obs.human <- observed[observed$group=="human" & observed$method=="ave", "coverage"]

	return(c(obs.mock, obs.soil, obs.mouse, obs.human))
}

coverage.table <- t(sapply(regions, getCoverage))
colnames(coverage.table) <- c("Mock", "Soil", "Mouse", "Human")
rownames(coverage.table) <- pretty.region[rownames(coverage.table)]
```

***Effects of error rates on OTU assignments.***
The sequencing error rate is known to affect the number of OTUs that are
observed {Schloss, 2011 #2466}. For each region, we determined that if there were no chimeras or
PCR or sequencing errors, then we would expect to find `r perfect.otu[[1]]` OTUs. When
achieved perfect chimera removal, but allowed for PCR and sequencing errors, we
observed between `r diff<-otu.table[,2]-perfect.otu;
round(min(diff), digits=1)` (`r names(which.min(diff))`) and `r round(max(diff), digits=1)`
(`r names(which.max(diff))`) extra OTUs. The range in the number of extra OTUs was largely
explained by the sequencing error rate (Pearson's R=`r round(cor.test(diff, final.error[,"precluster.error"])$estimate, 2)`). Next, we determined
the number of OTUs that were observed when we used UCHIME to identify chimeric sequence.
Under these more realistic conditions, we observed between `r diff<-otu.table[,3]-perfect.otu;
round(min(diff), digits=1)` (`r names(which.min(diff))`) and `r round(max(diff), digits=1)`
(`r names(which.max(diff))`) extra OTUs. Finally, we calculated the number of OTUs in the
soil, mouse, and human samples using the same pipeline with chimera detection and removal
based on the UCHIME algorithm. Again, we found that there was a strong correlation between
the number of observed OTUs and the error rate for the
soil (R=`r format(round(cor.test(otu.table[,"Soil"], final.error[,"precluster.error"])$estimate, 2), nsmall=2)`),
mouse (R=`r format(round(cor.test(otu.table[,"Mouse"], final.error[,"precluster.error"])$estimate, 2), nsmall=2)`),
and human samples (R=`r format(round(cor.test(otu.table[,"Human"], final.error[,"precluster.error"])$estimate, 2), nsmall=2)`).
These results underscore the effect of sequencing error on the inflation of the number of
observed OTUs.


```{r, classificationSummary}
data <- read.table(file="taxonomy.depth.analysis", header=T)

rdp <- cbind("Mock"=data[data$database=="rdp" & data$sample=="mock", "total"],
						 "Human"=data[data$database=="rdp" & data$sample=="human", "total"],
						 "Mouse"=data[data$database=="rdp" & data$sample=="mouse", "total"],
						 "Soil"=data[data$database=="rdp" & data$sample=="soil", "total"])
rownames(rdp) <- c("V4", "V3-V5", "V1-V3", "V1-V5", "V1-V6", "V1-V9")

gg <- cbind("Mock"=data[data$database=="gg" & data$sample=="mock", "total"],
						"Human"=data[data$database=="gg" & data$sample=="human", "total"],
						"Mouse"=data[data$database=="gg" & data$sample=="mouse", "total"],
						"Soil"=data[data$database=="gg" & data$sample=="soil", "total"])
rownames(gg) <- c("V4", "V3-V5", "V1-V3", "V1-V5", "V1-V6", "V1-V9")

silva <- cbind("Mock"=data[data$database=="silva" & data$sample=="mock", "total"],
							 "Human"=data[data$database=="silva" & data$sample=="human", "total"],
							 "Mouse"=data[data$database=="silva" & data$sample=="mouse", "total"],
							 "Soil"=data[data$database=="silva" & data$sample=="soil", "total"])
rownames(silva) <- c("V4", "V3-V5", "V1-V3", "V1-V5", "V1-V6", "V1-V9")

gg.sp <- cbind("Mock"=data[data$database=="gg" & data$sample=="mock", "X7"],
							 "Human"=data[data$database=="gg" & data$sample=="human", "X7"],
							 "Mouse"=data[data$database=="gg" & data$sample=="mouse", "X7"],
							 "Soil"=data[data$database=="gg" & data$sample=="soil", "X7"])
rownames(gg.sp) <- c("V4", "V3-V5", "V1-V3", "V1-V5", "V1-V6", "V1-V9")
```

***Increasing sequence length improves classification.***
We classified all of the sequence data we generated using the naïve Bayesian
classifier using the RDP, SILVA, and greengenes reference taxonomies (Figure
4). In general, increasing the length of the region improved the
ability to assign the sequence to a genus or species. Interestingly, each of the
samples we analyzed varied in the ability to assign its sequences to the depth of
genus or species. Furthermore, the reference database that did the best job of
classifying the sequences varied by sample type. For example, the SILVA
reference did the best for the human feces and soil samples and the RDP did the
best for the mouse feces samples. An advantage of the greengenes database is
that it contains
information for 2,514 species-level lineages for 11% of the reference sequences;
the other databases only provided taxonomic data to the genus level. There was a
modest association between the length of the fragment and the
ability to classify sequences to the species-level for the human samples; there
was no such association for the mouse and soil samples. In fact, at most
`r format(round(max(gg.sp[,"Soil"]), digits=1), nsmall=1)`% of
the soil sequences and `r format(round(max(gg.sp[,"Mouse"]), digits=1), nsmall=1)`%
of the mouse sequences could be classified to a
species. These results indicate that the ability to classify sequences to the
genus or species level is a function of read length, sample type, and the
reference database.  


```{r}
error <- read.table(file="analysis/v4/v4.trim.unique.good.filter.unique.pick.error.summary", header=T, row.names=1)
error.nochim <- error[error$numparents==1,]
one.off <- error.nochim[error.nochim$mismatches==1,]
one.off.sum <- sum(one.off$weight)
v4.table <- table(one.off$weight)
v4.total <- sum(error$weight)

error <- read.table(file="analysis/v35/v35.trim.unique.good.filter.unique.pick.error.summary", header=T, row.names=1)
error.nochim <- error[error$numparents==1,]
one.off <- error.nochim[error.nochim$mismatches==1,]
one.off.sum <- sum(one.off$weight)
v35.table <- table(one.off$weight)
v35.total <- sum(error$weight)

error <- read.table(file="analysis/v15/v15.trim.unique.good.filter.unique.pick.error.summary", header=T, row.names=1)
error.nochim <- error[error$numparents==1,]
one.off <- error.nochim[error.nochim$mismatches==1,]
one.off.sum <- sum(one.off$weight)
v15.table <- table(one.off$weight)
v15.total <- sum(error$weight)
```

***Sequencing errors are not random.***
Above, we described that although there was no obvious bias in the substitution
or insertion rate, we did observe that guanines and cytosines were more likely
to be deleted than adenines and thymidines. This lack of randomness in the error
profile suggested that there might be a systematic non-random distribution of
the errors across the sequences. This would manifest itself by the creation of
duplicate sequences with the same error. Because we were able to obtain a large
number of reads from the mock communities where we sequenced the V4
(N=`r v4.total`), V1-V5 (N=`r v15.total` sequences), and V3-V5 (N=`r v35.total`)
regions, we investigated the mock community data from these regions further. We
identified all of the sequences that had a 1-nt difference to the true sequence.
For these three regions, a majority of the sequences with 1-nt errors were only
observed once (V4: `r round(100*v4.table[1]/sum(v4.table), 1)`%, V1-V5:
`r round(100*v15.table[1]/sum(v15.table), 1)`%, V3-V5:
`r round(100*v35.table[1]/sum(v35.table), 1)`%). We found that the frequency of the
most abundant 1-nt error paralleled the number of sequences. There were two sequences
in the V4 dataset that occurred `r names(v4.table[length(v4.table)])` times, one
sequence in the V1-V5 dataset that occurred `r names(v15.table[length(v15.table)])`
times, and one sequence in the V3-V5 dataset that occurred
`r names(v35.table[length(v35.table)])` times. Contrary to previous reports
{Carneiro, 2012 #3458;Koren, 2012 #3459}, these results indicate that
reproducible errors occur with the PacBio sequencing platform and that they can be
quite frequent.


## Conclusions
The various sequencing platforms that are available to microbial ecologists are
able to fill unique needs and have their own strengths and weaknesses. For
sequencing the 16S rRNA gene, the 454 platform is able to generate a moderate
number of high-quality 500-nt sequence fragments (error rates below 0.02%) {Schloss, 2011 #2466} and
the MiSeq platform is able to generate a large number of high-quality 250-nt
sequence fragments (error rates below 0.02%) {Kozich, 2013 #2719}. The promise of the PacBio
sequencing platform was the generation of high-quality near full-length sequence
fragments. As we have shown in this study, it is possible to generate near
full-length sequences; however, the error rate associated with those reads is
considerable (i.e. `r round(100*final.error["v19","precluster.error"],2)`%)
and requires a level of sequencing coverage that is not commonly observed in a
typical sequencing run. This results in the generation of a small number of low
quality full-length sequences. When we considered the shorter V4 region, which is
similar in length to what is sequenced by the MiSeq platform, the error rates
we observed with the PacBio platform were nearly 5-fold higher than what has
previously been reported. It appears that the promise offered by the PacBio
platform has not been realized.

The widespread adoption of the 454 and MiSeq platforms and decrease in the use
of Sanger
sequencing for the 16S rRNA gene has resulted in a decrease in the
generation of the full-length reference sequences that are needed for performing
phylogenetic analyses and designing lineage specific PCR primers and fluorescent
*in situ* hybridization (FISH) probes. It remains to be determined whether the
elevated error rates we observed for full-length sequences are prohibitive for
these applications. We can estimate the distribution of errors assuming that the
errors follow a binomial distribution along the length of the 1,500 nt
gene with the error rate that we achieved from the V1-V9 mock community data
prior to pre-clustering the sequences, which was
`r round(100*final.error["v19","unique.error"],2)`% (Figure 5). Under
these conditions one would only expect
`r round(100*dbinom(0, 1500, final.error["v19","unique.error"]), 2)`% of the
sequences to have no errors. In fact, 95% of the reads would have at least
`r qbinom(0.05, 1500, final.error["v19","unique.error"])` errors and 50% of the
reads would have at least
`r qbinom(0.50, 1500, final.error["v19","unique.error"])` errors. If the error
rate could be dropped to 0.25%, then 95% of
the reads would have at least
`r qbinom(0.05, 1500, 0.0025)` error and 50% of the
reads would have at least
`r qbinom(0.50, 1500, 0.0025)` errors. If it were possible to replicate the low
error rates we have previously observed using the 454 and Illumina MiSeq
platforms, which was 0.02%, then we would expect
`r round(100*dbinom(0, 1500, 0.0002), 1)`% of the sequences to have no errors.
In fact, 95% of the reads would have `r qbinom(0.95, 1500, 0.0002)` or fewer
errors. Although full-length sequence data is highly desired, at this point, it
does not appear that the PacBio platform can provide the data of sufficient
quality to fill the niche of generating reference sequences.

Full-length sequences are frequently seen as a panacea to overcome the
limitations of taxonomic classifications. The ability to classify each of our
sample types benefited from the generation of full-length sequences. It was
interesting that the benefit varied by sample type and database. For example,
using the mouse libraries, the ability to classify each of the regions differed
by less than 5%
when classifying against the SILVA and greengenes databases. The effect of the
database that was used was also interesting. The RDP database outperformed the
other databases for the mouse samples and the SILVA database outperformed the
others for the human and soil samples. The three databases were equally
effective for classifying the mock community. Finally, since only the
greengenes database provided species-level information for its reference
sequences it was the only database that allowed for resolution of species-level
classification. The sequences from the mouse and soil libraries were not
effectively classified to the species level (all less than 10%). In contrast,
classification of the human libraries resulted in more than 40% of the sequences
being classified to a genus, regardless of the region. That the variation in
species-level classification for the human libraries was less than 10% suggests
that the benefit of added length is minimal considering the lower sequencing
yield.

The development of newer sequencing technologies continue to advance
and there is justifiable excitement to apply these technologies to sequence the
16S rRNA gene. Although it is clearly possible to generate sequencing data from
these various platforms, it is critical that we assess the platforms for their
ability to generate high quality data and the particular niche that the new
approach will fill. With this in mind, it is essential that researchers utilize
mock communities as part of their experimental design so that they can quantify
their error rates. The ability to generate large numbers of near full-length 16S
rRNA gene sequences is an exciting advance. At this point, the excitement must
be tempered by the appreciation that the error rates limit the application of
the approach.


## Acknowledgements
The Genomic DNA from Microbial Mock Community A (Even, Low Concentration, v3.1,
HM-278D) was obtained through the NIH Biodefense and Emerging Infections
Research Resources Repository, NIAID, NIH as part of the Human Microbiome
Project.


## Funding statement
This study was supported by grants from the NIH (R01HG005975, R01GM099514 and
P30DK034933 to PDS and U54HG004973 to SKH).


## References



## Tables

**Table 1. Summary of the primer pairs used to generate the 16S rRNA gene fragment fragments and the characteristics of each region.**

```{r Table_1, warning=TRUE, results='asis'}

getSloppyRevComp <- function(sequence){
	rev.sequence <- paste(rev(unlist(strsplit(sequence, ""))), collapse="")
	revcomp.sequence <- chartr("ATGCRYSWKMBDHVN", "TACG...........", rev.sequence)
	return(revcomp.sequence)
}

getPos <- function(primer, sequence=ecoli, forward=TRUE){
	if(forward==FALSE){
		primer <- getSloppyRevComp(primer)
	}
	primer <- gsub("[^ATGC]", ".", primer)

	pos <- regexpr(primer, sequence)

	if(forward==FALSE){
		pos <- pos + nchar(primer) -1
	}
	return(pos)

}

#taken from... http://www.ncbi.nlm.nih.gov/nuccore/NC_022648.1?report=fasta&from=4564120&to=4565661
ecoli <- "AAATTGAAGAGTTTGATCATGGCTCAGATTGAACGCTGGCGGCAGGCCTAACACATGCAAGTCGAACGGTAACAGGAAGCAGCTTGCTGCTTTGCTGACGAGTGGCGGACGGGTGAGTAATGTCTGGGAAACTGCCTGATGGAGGGGGATAACTACTGGAAACGGTAGCTAATACCGCATAACGTCGCAAGACCAAAGAGGGGGACCTTCGGGCCTCTTGCCATCGGATGTGCCCAGATGGGATTAGCTAGTAGGTGGGGTAACGGCTCACCTAGGCGACGATCCCTAGCTGGTCTGAGAGGATGACCAGCCACACTGGAACTGAGACACGGTCCAGACTCCTACGGGAGGCAGCAGTGGGGAATATTGCACAATGGGCGCAAGCCTGATGCAGCCATGCCGCGTGTATGAAGAAGGCCTTCGGGTTGTAAAGTACTTTCAGCGGGGAGGAAGGGAGTAAAGTTAATACCTTTGCTCATTGACGTTACCCGCAGAAGAAGCACCGGCTAACTCCGTGCCAGCAGCCGCGGTAATACGGAGGGTGCAAGCGTTAATCGGAATTACTGGGCGTAAAGCGCACGCAGGCGGTTTGTTAAGTCAGATGTGAAATCCCCGGGCTCAACCTGGGAACTGCATCTGATACTGGCAAGCTTGAGTCTCGTAGAGGGGGGTAGAATTCCAGGTGTAGCGGTGAAATGCGTAGAGATCTGGAGGAATACCGGTGGCGAAGGCGGCCCCCTGGACGAAGACTGACGCTCAGGTGCGAAAGCGTGGGGAGCAAACAGGATTAGATACCCTGGTAGTCCACGCCGTAAACGATGTCGACTTGGAGGTTGTGCCCTTGAGGCGTGGCTTCCGGAGCTAACGCGTTAAGTCGACCGCCTGGGGAGTACGGCCGCAAGGTTAAAACTCAAATGAATTGACGGGGGCCCGCACAAGCGGTGGAGCATGTGGTTTAATTCGATGCAACGCGAAGAACCTTACCTGGTCTTGACATCCACGGAAGTTTTCAGAGATGAGAATGTGCCTTCGGGAACCGTGAGACAGGTGCTGCATGGCTGTCGTCAGCTCGTGTTGTGAAATGTTGGGTTAAGTCCCGCAACGAGCGCAACCCTTATCCTTTGTTGCCAGCGGTCCGGCCGGGAACTCAAAGGAGACTGCCAGTGATAAACTGGAGGAAGGTGGGGATGACGTCAAGTCATCATGGCCCTTACGACCAGGGCTACACACGTGCTACAATGGCGCATACAAAGAGAAGCGACCTCGCGAGAGCAAGCGGACCTCATAAAGTGCGTCGTAGTCCGGATTGGAGTCTGCAACTCGACTCCATGAAGTCGGAATCGCTAGTAATCGTGGATCAGAATGCCACGGTGAATACGTTCCCGGGCCTTGTACACACCGCCCGTCACACCATGGGAGTGGGTTGCAAAAGAAGTAGGTAGCTTAACCTTCGGGAGGGCGCTTACCACTTTGTGATTCATGACTGGGGTGAAGTCGTAACAAGGTAACCGTAGGGGAACCTGCGGTTGGATCACCTCCTTA"



oligos <- read.table(file="pacbio.oligos", stringsAsFactors=F)[1:6,]
rownames(oligos) <- pretty.region[oligos$V4]
oligos <- oligos[,c("V2", "V3")]
colnames(oligos) <- c("Forward", "Reverse")

start <- sapply(oligos[,1], getPos)
end <- sapply(oligos[,2], getPos, forward=FALSE)


coordinates <- paste(start, end, sep="-")
length <- end - start - nchar(oligos[,1]) - nchar(oligos[,2]) + 1
t1 <- cbind(oligos, coordinates, length)
knitr::kable(t1, digits=1, row.names=TRUE, col.names=c("Forward", "Reverse", "*E. coli* coordinates^a^", "Length (bp)^b^"), align=c("l", "l", "c", "c"))
```

^a^	The coordinates where the start and end of the forward and reverse primers anneal, respectively.

^b^	The number of bases between the primers.



**Table 2. Summary of the reasons that sequences were excluded because of the
basic sequence curation steps**

```{r Table_2, warning=TRUE, results='asis'}
rownames(reasons.lost) <- pretty.region[rownames(reasons.lost)]
reasons.lost <- cbind(orig.nseqs, 100*reasons.lost, basic.nseqs)
knitr::kable(reasons.lost, digits=1, row.names=TRUE,
						 col.names=c("Initial sequences (N)", "Good reads (%)",
						 						"Wrong start/end position (%)",
						 						"Excessively long homopolymers (%)",
						 						"Ambiguous base calls (%)",
						 						"Sequences remaining (N\\)"),
						 align="c")
```


## Figures

**Figure 1. Summary of errors in data generated using PacBio sequencing platform
to sequence various regions within the 16S rRNA gene.** Quality scores varied
with error types (A). The sequencing error rate of the amplified gene fragments
increased with mismatches to the barcodes and primers (B). The sequencing error
rate declined with increasd sequencing coverage; however, increasing the
sequencing depth beyond 10-fold coverage had no meaningful effect on the
sequencing error rate (C).


**Figure 2. Change in error rate (A) and the percentage of sequences that were
retained (B) when using various sequence curation methods.** The condition that
was used for downstream analyses is indicated by the star. The plotted numbers
represent the region that was sequenced. For example "15" represents the data
for the V1-V5 region.


**Figure 3. The relationship between the error rate of each region and the
composite quality scores for the sequences.** The error rates (A and C) and
percentage of sequences (B and D) were calculated for the reads that had a
composite quality score above the plotted value. The composite quality scores
were calculated by either determining the minimum value of the average quality
score wihin all 50-nt windows within each region (A and B) or by calculating
the average quality score across the entire sequence read (C and D).


**Figure 4. Percentage of unique sequences that could be classified.**
Classifications were performed using taxonomy references curated from the RDP,
SILVA, or greengenes databases for the four types of samples that were sequenced
across the six regions from the 16S rRNA gene. Only the greengenes taxonomy
reference provided species-level information.

**Figure 5. The percentage of V1-V9 sequences that were predicted to have
between 0 and 20 errors as a function of the error rate of the sequences.** The
highest error rate, `r round(100*final.error["v19","unique.error"], 2)`%,
corresponds to what was observed before the pre-clustering step.
The smallest error rate (0.02%) corresponds to our previous observations using
the 454 and MiSeq sequencing platforms. The predicted number of errors was
assumed to follow a binomial distribution.



### Figure 1
```{r Figure_1, fig.width=6.5, fig.height=3.0}
layout(matrix(c(1,2,3), nrow=1), heights=1, widths=c(0.75,1,1))


#Panel A depicting range of quality scores for different errors
par(mar=c(6, 5, 0.5, 0.5))
plot(1, xlim=c(0.5, 4.5), ylim=c(0,75), type="n", yaxt="n", xaxt="n", xlab="",
		 ylab="")
polygon(x=c(0.75, 1.25, 1.25, 0.75), y=c(m.quant["25%"], m.quant["25%"],
																				 m.quant["75%"], m.quant["75%"]))
polygon(x=c(1.75, 2.25, 2.25, 1.75), y=c(s.quant["25%"], s.quant["25%"],
																				 s.quant["75%"], s.quant["75%"]))
polygon(x=c(2.75, 3.25, 3.25, 2.75), y=c(i.quant["25%"], i.quant["25%"],
																				 i.quant["75%"], i.quant["75%"]))
polygon(x=c(3.75, 4.25, 4.25, 3.75), y=c(a.quant["25%"], a.quant["25%"],
																				 a.quant["75%"], a.quant["75%"]))

segments(x0=seq(0.75, 3.75, 1), x1=seq(1.25,4.25,1), y0=c(m.quant["50%"],
											s.quant["50%"], i.quant["50%"], a.quant["50%"]), lwd=4)

arrows(x0=1:4, y0=c(m.quant["75%"], s.quant["75%"], i.quant["75%"],
										a.quant["75%"]), y1=c(m.quant["97.5%"], s.quant["97.5%"],
																					i.quant["97.5%"], a.quant["97.5%"]),
			 angle=90, length=0.05)

arrows(x0=1:4, y0=c(m.quant["25%"], s.quant["25%"], i.quant["25%"],
										a.quant["25%"]), y1=c(m.quant["2.5%"], s.quant["2.5%"],
																					i.quant["2.5%"], a.quant["2.5%"]),
			 angle=90, length=0.05)

axis(1, at=c(1,2,3,4), label=c("Matches", "Substitutions", "Insertions",
															 "Ambiguous"), las=2, cex.axis=1)
axis(2, las=2, at=c(0,25,50,75), cex.axis=1.5)
title(ylab="Quality score", cex.lab=1.5)
mtext(side=2, line=2.5, at=75, text="A", cex=2, font=2, las=2)


#Panel B depicting relationship between errors in barcodes/primers and the
#rest of the sequence.
par(mar=c(5,5,0.5,0.5))
plot(err.bcprimer$x[1:6,1]~err.bcprimer$Group.1[1:6], pch=19,
		 ylab="Error rate (%)", xlab="", axes=F, ylim=c(0,5), cex.lab=1.5)
mtext(side=1, line=3.75, text="Total mismatches to\nbarcodes and primers",
			cex=0.9)
axis(1, cex.axis=1.5)
axis(2, las=2, cex.axis=1.5)
box()
mtext(side=2, line=2.5, at=5, text="B", cex=2, font=2, las=2)


#Panel C depicting relationship between sequencing coverage and error rate for
#the different regions that were sequence
plotLines <- function(folder){
	composite <- read.table(file=paste("pipeline_dev/", folder, "/", folder,
																		 ".composite", sep=""),
													header=T,row.names=1)

	composite <- composite[composite$reason=="g",]
	error.by.depth <- aggregate(composite$error, by=list(composite$freq),
															function(x){c(mean=mean(x),
																						quantile(x, prob=c(0.025, 0.975)),
																						n=length(x))})

	#exclude any coverage values where we don't have at least 50 observations
	error.by.depth <- error.by.depth[error.by.depth$x[,"n"]>=50,]
	fold.coverage <- error.by.depth[, "Group.1"]
	error.by.depth <- error.by.depth$x

	mean <- error.by.depth[,"mean"]
	points(mean~fold.coverage, type="l", lwd=2, col=clrs[folder])
}

par(mar=c(5,2,0.5, 0.5))
plot(1, xlim=c(2,30), ylim=c(0,0.05), type="n", xlab="", ylab="", axes=F)
axis(2, at=seq(0,0.05, 0.01), label=FALSE, tick=T, las=2)
#axis(2, at=seq(0,0.05, 0.01), label=seq(0,5, 1), las=2)
axis(1, cex.axis=1.5)
lapply(regions, plotLines)
legend(x=18, y=0.05, legend=pretty.region[regions], lty=1, lwd=2, col=clrs[regions])
mtext(side=2, line=0.5, at=0.05, text="C", cex=2, font=2, las=2)
title(xlab="Coverage", ylab="", cex.lab=1.5)
box()

layout(1)
```



### Figure 2
```{r Figure_2, width=6.5, height=6}
error.fraction <- cbind(initial.error=init.rates, basic.error=basic.error,
												bcprimer.error, coverage.error, aveq.error,
												oligosCoverage.error, oligosQScore.error,
												coverageQScore.error, allFilters.error, final.error)
rownames(error.fraction) <- gsub("v(\\d*)", "\\1", rownames(error.fraction))

error <- 100 * error.fraction[,grepl("error", colnames(error.fraction))]
fraction <- 100 * error.fraction[,grepl("frac", colnames(error.fraction))]

getJitter <- function(x){
	jitter <- 0.15
	runif(6, x-jitter, x+jitter)
}

l <- layout(matrix(c(1,2,3), nrow=3), heights=c(1,1,0.6))

par(mar=c(0.5, 7, 0.5, 0.5))
plot(1, type="n", xlim=c(1, 14), ylim=c(0,2.5), axes=F, xlab="", ylab="",
		 cex.lab=1.5)
text(x=getJitter(1.0), y=error[,1], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(2.0), y=error[,2], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(3.0), y=error[,3], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(4.0), y=error[,4], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(5.0), y=error[,5], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(6.0), y=error[,6], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(7.0), y=error[,7], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(8.0), y=error[,8], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(9.0), y=error[,9], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(10.0), y=error[,10], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(11.0), y=error[,11], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(12.0), y=error[,12], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(13.0), y=error[,13], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(14.0), y=error[,15], label=rownames(error.fraction), cex=1.25)
text(x=10, y=2, label="*", cex=3, font=2)

mtext(text="Error rate (%)", side=2, line=4, cex.lab=1.2)
box()
axis(2, las=2, at=seq(0,2.5, 0.5), label=format(seq(0, 2.5, 0.5),nsmall=1),
		 cex.axis=1.5)

abline(v=seq(3.5,13.5, 1), col="grey")
abline(v=c(1.5, 2.5, 13.5), col="black", lwd=2)

mtext(side=2, line=4.5, at=2.44, text="A", cex=2, font=2, las=1)

par(mar=c(0.5, 7, 0.5, 0.5))
plot(1, type="n", xlim=c(1, 14), ylim=c(0,100), axes=F,
		 ylab="Reads remaining\nfrom basic criteria (%)", xlab="", cex.lab=1.5)
text(x=getJitter(3.0), y=fraction[,1], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(4.0), y=fraction[,2], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(5.0), y=fraction[,3], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(6.0), y=fraction[,4], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(7.0), y=fraction[,5], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(8.0), y=fraction[,6], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(9.0), y=fraction[,7], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(10.0), y=fraction[,8], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(11.0), y=fraction[,9], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(12.0), y=fraction[,10], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(13.0), y=fraction[,11], label=rownames(error.fraction), cex=1.25)
text(x=getJitter(14.0), y=fraction[,8], label=rownames(error.fraction), cex=1.25)

box()
abline(v=seq(3.5,13.5, 1), col="grey")
abline(v=c(1.5, 2.5, 13.5), col="black", lwd=2)

mtext(side=2, line=4.5, at=98, text="B", cex=2, font=2, las=1)
axis(2, las=2, at=seq(0,100, 25), label=seq(0, 100, 25), cex.axis=1.5)
text(1,0, label="NA")
text(2,0, label="NA")

plot(1, type="n", xlim=c(1, 14), ylim=c(0,1), axes=F, ylab="", xlab="")

text(x=c(1:14)+0.2, y=rep(1, 11), label=c("Initial data", "Basic criteria",
		"No Mismatches", "\u22641 Mismatch", "Coverage", "Quality Score",
		"No Mismatches\n& Coverage", "\u22641 Mismatch\n& Coverage",
		"No Mismatches\n& Quality", "\u22641 Mismatch\n& Quality",
		"Coverage & Quality", "No Mismatches,\nCoverage & Quality",
		"\u22641 Mismatch,\nCoverage & Quality", "After Pre-clustering"),
		srt=90, pos=2, cex=1)  

layout(1)
```




### Figure 3
```{r Figure_3, fig.height=6.5, fig.width=6.5}
aggregateErrorMinQualityScore <- function(folder){
	write(folder, "")
	composite <- read.table(file=paste("pipeline_dev/", folder, "/", folder,
																		 ".composite", sep=""), header=T,
													row.names=1)
	composite <- composite[composite$reason == "g",]

	remaining.error <- rep(0, max(composite$minQ)+1)
	qscores <- 0:max(composite$minQ)

	remaining.error <- unlist(lapply(qscores,
														function(x){mean(composite[composite$minQ >= x,"error"])}))
	names(remaining.error) <- qscores
	points(x=10:70, remaining.error[10:70], type="l", col=clrs[folder], lwd=2)
}

fractionMinQualityScore <- function(folder){
	write(folder, "")

	composite <- read.table(file=paste("pipeline_dev/", folder, "/", folder,
																		 ".composite", sep=""), header=T, row.names=1)
	composite <- composite[composite$reason == "g",]

	binned <- aggregate(composite$error, by=list(round(composite$minQ)), length)
	remaining <- 1-cumsum(binned$x)/sum(binned$x)
	points(binned$Group.1, remaining, type="l", col=clrs[folder], lwd=2)
}


aggregateErrorAveQualityScore <- function(folder){
	write(folder, "")
	composite <- read.table(file=paste("pipeline_dev/", folder, "/", folder,
																		 ".composite", sep=""), header=T, row.names=1)
	composite <- composite[composite$reason == "g",]

	remaining.error <- rep(0, max(composite$aveQ)+1)
	qscores <- 0:max(composite$aveQ)
	remaining.error <- unlist(lapply(qscores,
												function(x){mean(composite[composite$aveQ >= x,"error"])}))
	names(remaining.error) <- qscores
	points(x=10:70, remaining.error[10:70], type="l", col=clrs[folder], lwd=2)
}


fractionAveQualityScore <- function(folder){
write(folder, "")

	composite <- read.table(file=paste("pipeline_dev/", folder, "/", folder,
																		 ".composite", sep=""), header=T, row.names=1)
	composite <- composite[composite$reason == "g",]

	binned <- aggregate(composite$error, by=list(round(composite$aveQ)), length)

	remaining <- 1-cumsum(binned$x)/sum(binned$x)
	points(binned$Group.1, remaining, type="l", col=clrs[folder], lwd=2)
}

layout(1)
layout(matrix(c(1,2,3,4), nrow=2, byrow=F), width=c(1.1,1), height=c(1, 1.3))

#A
par(mar=c(0.5,5,0.5, 0.5))
plot(1, xlim=c(10,75), ylim=c(0,0.015), type="n", axes=F, xlab="", ylab="")
lapply(regions, aggregateErrorMinQualityScore)
mtext(side=2, line=2.5, text="Error rate of sequences\nabove threshold (%)", cex.lab=0.9)
axis(1, at=seq(10,70,10), label=F, tick=T)
axis(2, las=2, at=seq(0,0.015,0.005), label=format(seq(0,1.5,0.5), nsmall=1), cex.axis=1.25)
box()
mtext(side=2, line=2.6, at=0.015, text="A", las=2, cex=2, font=2)


#B
par(mar=c(6,5,0.5, 0.5))
plot(1, xlim=c(10,75), ylim=c(0,1), type="n", yaxt="n", xlab="", ylab="", cex.axis=1.25)
lapply(regions, fractionMinQualityScore)
mtext(side=1, line=4.25, text="Minimum average quality\nscore within a 50-nt window\nacross the full sequence", cex=0.9)
mtext(side=2, line=2.5, text="Sequences above\nthreshold (%)", cex.lab=0.9)

axis(2, las=2, at=seq(0,1,0.2), label=seq(0,100,20), cex.axis=1.25)
mtext(side=2, line=2.6, at=1, text="B", las=2, cex=2, font=2)


#C
par(mar=c(0.5,2,0.5, 0.5))
plot(1, xlim=c(10,75), ylim=c(0,0.015), type="n", axes=F, xlab="", ylab="")
lapply(regions, aggregateErrorAveQualityScore)
axis(1, at=seq(10,70,10), label=F, tick=T)
axis(2, at=seq(0,0.02,0.005), label=F, tick=T)
box()
mtext(side=2, line=0.6, at=0.015, text="C", las=2, cex=2, font=2)


#D
par(mar=c(6,2,0.5, 0.5))
plot(1, xlim=c(10,75), ylim=c(0,1), type="n", yaxt="n", xlab="", ylab="", cex.axis=1.25)
lapply(regions, fractionAveQualityScore)
mtext(side=1, text="Average quality score", cex=0.9, line=3)
title(ylab="Sequences above threshold (%)")
axis(2, at=seq(0,1,0.2), label=FALSE, tick=TRUE)
mtext(side=2, line=0.6, at=1, text="D", las=2, cex=2, font=2)

legend(x=10, y=0.50, legend=pretty.region[regions], lty=1, lwd=2, col=clrs[regions], cex=1.0)
```


### Figure 4

```{r, Figure_4, fig.width=7, fig.height=7}
par(mar=c(5, 5, 0.5, 1))
dotchart(gg, xlim=c(0,100), col="black", xlab="Unique reads that classified\nto genus or species level (%)", pch=19)

points(x=rdp[,"Mock"], y=25:30, pch=15, col="black")
points(x=rdp[,"Human"], y=17:22, pch=15, col="black")
points(x=rdp[,"Mouse"], y=9:14, pch=15, col="black")
points(x=rdp[,"Soil"], y=1:6, pch=15, col="black")

points(x=silva[,"Mock"], y=25:30, pch=17, col="black")
points(x=silva[,"Human"], y=17:22, pch=17, col="black")
points(x=silva[,"Mouse"], y=9:14, pch=17, col="black")
points(x=silva[,"Soil"], y=1:6, pch=17, col="black")

points(x=gg.sp[,"Mock"], y=25:30, pch=21, bg="gray")
points(x=gg.sp[,"Human"], y=17:22, pch=21, bg="gray")
points(x=gg.sp[,"Mouse"], y=9:14, pch=21, bg="gray")
points(x=gg.sp[,"Soil"], y=1:6, pch=21, bg="gray")

legend(x=63, y=12, legend=c("RDP (gen.)", "SILVA (gen.)", "greengenes (gen.+sp.)", "greengenes (sp.)"), pch=c(15, 17, 19, 21), col="black", pt.bg=c("black", "black", "black", "gray"), bg="white")
```



### Figure 5

```{r Figure_5, fig.width=7, fig.height=4}
x <- 0:20
e1 <- final.error["v19","unique.error"]
e2 <- 0.0025
e3 <- 0.0010
e4 <- 0.0002

par(mar=c(5,6,0.5, 0.5))
plot(x, dbinom(x, 1458, e1), type="l", ylim=c(0,0.35), xlab="Number of errors",
		 ylab="Full-length 16S rRNA\ngene sequences (%)", yaxt="n", lwd=3)
points(x, dbinom(x, 1458, e2), type="l", col="red", lwd=3)
points(x, dbinom(x, 1458, e3), type="l", col="blue", lwd=3)
points(x, dbinom(x, 1458, e4), type="l", col="darkgreen", lwd=3)
axis(2, at=seq(0,0.35,0.05), label=seq(0,35,5), las=1)
legend(x=12, y=0.30, legend=paste0(format(round(100*c(e1, e2, e3, e4), 2), nsmall=2), "%"),
			 lwd=3, col=c("black", "red", "blue", "darkgreen"))
```





```{r, versions}
sessionInfo()
```
